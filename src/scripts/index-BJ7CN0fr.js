(function(){const e=document.createElement("link").relList;if(e&&e.supports&&e.supports("modulepreload"))return;for(const o of document.querySelectorAll('link[rel="modulepreload"]'))a(o);new MutationObserver(o=>{for(const t of o)if(t.type==="childList")for(const n of t.addedNodes)n.tagName==="LINK"&&n.rel==="modulepreload"&&a(n)}).observe(document,{childList:!0,subtree:!0});function s(o){const t={};return o.integrity&&(t.integrity=o.integrity),o.referrerPolicy&&(t.referrerPolicy=o.referrerPolicy),o.crossOrigin==="use-credentials"?t.credentials="include":o.crossOrigin==="anonymous"?t.credentials="omit":t.credentials="same-origin",t}function a(o){if(o.ep)return;o.ep=!0;const t=s(o);fetch(o.href,t)}})();class d{addTask(e){console.log("Task added:",e)}}class g{constructor(){}initialize(){console.log("Workflow initialized.")}run(){console.log("Workflow running...")}}class u{log(e,s){console.log("Log:",e)}}class f{scanDirectory(e){return console.log("Scanning directory:",e),[]}getCategorizedResults(){return{images:[],documents:[]}}}class m{processLargeFile(e){console.log("Processing large file:",e)}}class p{extract(e){return console.log("Extracting metadata for:",e),{}}}class y{handleError(e){console.error("Error handled:",e)}}const c=new u,l=new d,w=new g,i=new f,h=new m,P=new p,L=new y;async function x(){try{i.scanDirectory("/Users/jbear/dev/base_project/nexxus_seed");const r=i.getCategorizedResults();for(const e of r.documents)await h.processLargeFile(e);for(const e of r.images){const s=P.extract(e);s&&c.log(`Metadata extracted for ${e}:`,s)}l.addTask(()=>Promise.resolve({type:"imageProcessing",payload:r.images})),l.addTask(()=>Promise.resolve({type:"documentProcessing",payload:r.documents})),await w.run(),c.log("Workflow completed successfully.")}catch(r){L.handleError(r)}}x();
